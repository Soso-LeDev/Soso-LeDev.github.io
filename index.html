<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Reconnaissance faciale — Contrôle vocal</title>
<style>
  html,body{height:100%;margin:0;background:#000;color:#fff;font-family:Inter,system-ui,Arial;overflow:hidden}
  video,canvas{position:fixed;inset:0;width:100vw;height:100vh;object-fit:cover}
  #status{position:fixed;left:12px;bottom:12px;background:rgba(0,0,0,0.5);color:#00ff99;padding:8px 10px;border-radius:10px;border:1px solid rgba(0,255,153,0.08);font-size:13px}
  #transcript{position:fixed;left:12px;bottom:60px;color:#00ff99;opacity:0.9;font-size:13px;max-width:60vw;word-break:break-word}
  #speech-bubble{position:fixed;left:50%;transform:translateX(-50%);bottom:120px;background:rgba(0,255,153,0.06);color:#00ff99;padding:10px 14px;border-radius:12px;border:1px solid rgba(0,255,153,0.12);display:none;max-width:80%;text-align:center}
  /* éléments cachés pour accessibilité tactile (on ne doit pas toucher) */
  .hidden-ui{display:none}
</style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>
  <div id="status">Initialisation…</div>
  <div id="transcript"></div>
  <div id="speech-bubble"></div>

  <!-- face-api vladmandic -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>

  <script>
  (async ()=>{

    // === Configuration ===
    const API_KEY_GROQ = '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'; // laissé côté client comme demandé
    const activationPrefixes = ['krozen','frozen','crozen']; // commandes vocales commencent par l'un d'eux
    const statusEl = document.getElementById('status');
    const transcriptEl = document.getElementById('transcript');
    const speechBubble = document.getElementById('speech-bubble');
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');

    let isRunning = false;
    let faceMatcher = null;
    let labeledDescriptors = []; // {label, descriptors: [Float32Array,...]}
    let detectionMode = 'tiny'; // tiny par défaut (rapide)
    let detectionOptions = new faceapi.TinyFaceDetectorOptions({ inputSize: 320, scoreThreshold: 0.5 });
    let mediaRecorder = null;
    let recordedBlobs = [];

    // resize canvas to video when available
    function resizeCanvas(){
      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;
    }
    window.addEventListener('resize', resizeCanvas);
    resizeCanvas();

    // --- TTS helper ---
    function speak(text){
      try {
        const s = new SpeechSynthesisUtterance(text);
        s.lang = 'fr-FR';
        speechSynthesis.cancel(); // avoid overlap
        speechSynthesis.speak(s);
      } catch(e){ console.warn('TTS failed', e); }
      // show bubble briefly
      speechBubble.textContent = text;
      speechBubble.style.display = 'block';
      clearTimeout(speechBubble._t);
      speechBubble._t = setTimeout(()=> speechBubble.style.display = 'none', 6000);
    }

    // --- status helper ---
    function setStatus(t){ statusEl.textContent = t; }

    // === Load face-api models ===
    async func
