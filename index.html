<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Détection Visages - Webcam Live (OpenCV.js)</title>
    <script async src="https://docs.opencv.org/4.10.0/opencv.js" onload="onOpenCvReady();"></script>
    <style>
        body { margin: 0; font-family: Arial; text-align: center; background: #f0f0f0; }
        #videoInput { width: 640px; height: 480px; border: 2px solid #ccc; display: none; }
        #canvasOutput { width: 640px; height: 480px; border: 2px solid #ccc; display: none; }
        #status { margin: 10px; font-size: 18px; color: #333; }
        button { padding: 10px 20px; font-size: 16px; background: #4CAF50; color: white; border: none; cursor: pointer; }
        button:hover { background: #45a049; }
        button:disabled { background: #ccc; cursor: not-allowed; }
    </style>
</head>
<body>
    <h1>Détection de Visages en Live</h1>
    <p id="status">Chargement OpenCV.js... Clique pour autoriser la caméra.</p>
    <br>
    <button id="startBtn" onclick="requestCamera()">Autoriser la Caméra</button>
    <video id="videoInput" autoplay muted></video>
    <canvas id="canvasOutput"></canvas>
    <br>
    <button id="stopBtn" onclick="stopDetection()" style="display: none;">Arrêter</button>

    <script>
        let videoInput = document.getElementById('videoInput');
        let canvasOutput = document.getElementById('canvasOutput');
        let status = document.getElementById('status');
        let startBtn = document.getElementById('startBtn');
        let stopBtn = document.getElementById('stopBtn');
        let stream = null;
        let faceCascade = new cv.CascadeClassifier();
        let detectionInterval = null;

        function onOpenCvReady() {
            console.log('OpenCV.js prêt !');
            loadCascade();
        }

        function loadCascade() {
            let cascadeUrl = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml';
            let xhr = new XMLHttpRequest();
            xhr.open('get', cascadeUrl, true);
            xhr.responseType = 'arraybuffer';
            xhr.onload = function() {
                let data = new Uint8Array(xhr.response);
                cv.FS_createDataFile('/', 'haarcascade_frontalface_default.xml', data, true, false, false);
                faceCascade.load('haarcascade_frontalface_default.xml');
                status.textContent = 'Cascade chargée ! Clique pour autoriser la caméra.';
            };
            xhr.onerror = function() {
                status.textContent = 'Erreur chargement cascade. Vérifie ta connexion.';
            };
            xhr.send();
        }

        function requestCamera() {
            startBtn.disabled = true;
            startBtn.textContent = 'Autorisation en cours...';
            status.textContent = 'Demande d\'accès à la caméra...';

            navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } })
                .then(handleSuccess)
                .catch(handleError);
        }

        function handleSuccess(s) {
            stream = s;
            videoInput.srcObject = stream;
            videoInput.style.display = 'block';
            canvasOutput.style.display = 'block';
            startBtn.style.display = 'none';
            stopBtn.style.display = 'inline-block';
            status.textContent = 'Caméra activée ! Détection en cours...';

            videoInput.onloadedmetadata = function() {
                canvasOutput.width = videoInput.videoWidth;
                canvasOutput.height = videoInput.videoHeight;
                detectionInterval = setInterval(processVideo, 30);  // 30ms pour tracking fluide
            };
        }

        function processVideo() {
            let src = cv.imread(videoInput);
            let gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
            let faces = new cv.RectVector();
            let msize = new cv.Size(0, 0);
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, msize);

            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                let point1 = new cv.Point(face.x, face.y);
                let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                cv.rectangle(src, point1, point2, [0, 255, 0, 255], 3);  // Vert épais
            }

            cv.imshow('canvasOutput', src);
            src.delete(); gray.delete(); faces.delete();
            status.textContent = `Visages détectés : ${faces.size()} (carré suit en live)`;
        }

        function handleError(err) {
            startBtn.disabled = false;
            startBtn.textContent = 'Autoriser la Caméra';
            let errorMsg = 'Erreur caméra : ';
            if (err.name === 'NotAllowedError') {
                errorMsg += 'Refusé. Réessaie ou check params (HTTPS requis).';
            } else if (err.name === 'NotFoundError') {
                errorMsg += 'Pas de caméra. Vérifie hardware.';
            } else {
                errorMsg += err.message;
            }
            status.textContent = errorMsg;
        }

        function stopDetection() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            if (detectionInterval) {
                clearInterval(detectionInterval);
            }
            videoInput.style.display = 'none';
            canvasOutput.style.display = 'none';
            stopBtn.style.display = 'none';
            startBtn.style.display = 'inline-block';
            startBtn.disabled = false;
            startBtn.textContent = 'Autoriser la Caméra';
            status.textContent = 'Arrêté. Clique pour recommencer.';
        }
    </script>
</body>
</html>
