<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Visage — ligne & carré en temps réel</title>
  <style>
    html,body{height:100%;margin:0;background:#000;color:#fff;font-family:Arial,Helvetica,sans-serif}
    #container{position:relative;width:100vw;height:100vh;overflow:hidden}
    video{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover}
    canvas{position:absolute;top:0;left:0;/* taille mise dynamiquement */ pointer-events:none}
    #hud{position:fixed;left:12px;top:12px;background:rgba(0,0,0,0.6);padding:8px;border-radius:8px;font-size:13px;z-index:40}
  </style>

  <!-- TFJS + BlazeFace -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>
</head>
<body>
  <div id="container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>
  <div id="hud">Initialisation… (Ouvre la console pour debug)</div>

<script>
(async () => {
  const video = document.getElementById('video');
  const canvas = document.getElementById('overlay');
  const ctx = canvas.getContext('2d');
  const hud = document.getElementById('hud');
  let model = null;

  // --- Setup camera ---
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" }, audio: false });
    video.srcObject = stream;
    await new Promise(resolve => video.onloadedmetadata = resolve);
    video.play();
  } catch (e) {
    hud.textContent = "Erreur accès caméra: " + (e.message || e);
    console.error(e);
    return;
  }

  // --- Align canvas pixel coords to displayed video ---
  function syncCanvasToVideo() {
    // taille réelle (pixels) de la vidéo source
    const vw = video.videoWidth || video.clientWidth;
    const vh = video.videoHeight || video.clientHeight;
    canvas.width = vw;
    canvas.height = vh;
    // taille CSS du canvas pour couvrir l'élément vidéo affiché (client size)
    canvas.style.width = video.clientWidth + 'px';
    canvas.style.height = video.clientHeight + 'px';
    // position du canvas (au cas où video est centré/croppé)
    const rect = video.getBoundingClientRect();
    canvas.style.left = rect.left + 'px';
    canvas.style.top = rect.top + 'px';
  }
  window.addEventListener('resize', syncCanvasToVideo);
  syncCanvasToVideo();

  // --- wait for blazeface global + load model ---
  function waitForGlobal(name, ms = 7000, interval = 100) {
    return new Promise((resolve, reject) => {
      if (window[name]) return resolve(window[name]);
      const t = setInterval(() => { if (window[name]) { clearInterval(t); resolve(window[name]); } }, interval);
      setTimeout(() => { clearInterval(t); reject(new Error(name + " introuvable")); }, ms);
    });
  }

  try {
    await waitForGlobal('blazeface', 7000);
    model = await blazeface.load();
    hud.textContent = "Modèle chargé ✅";
    console.log("BlazeFace chargé");
  } catch (err) {
    hud.textContent = "Erreur chargement modèle: " + (err.message || err);
    console.error(err);
    return;
  }

  // --- util heuristique : estimer yeux depuis bbox si pas de landmarks ---
  function estimateEyesFromBox(box) {
    const [x1,y1] = box.topLeft;
    const [x2,y2] = box.bottomRight;
    const w = x2 - x1;
    const h = y2 - y1;
    // heuristique : yeux à ~35% de la hauteur depuis le top, à 30% et 70% du width
    const left = [ x1 + w*0.3, y1 + h*0.35 ];
    const right = [ x1 + w*0.7, y1 + h*0.35 ];
    return [left, right];
  }

  // --- Draw loop ---
  async function loop() {
    syncCanvasToVideo(); // garde aligné
    if (!model || video.readyState < 2) { requestAnimationFrame(loop); return; }

    try {
      // estimateFaces retourne coords en pixels relatifs à l'input (video)
      const preds = await model.estimateFaces(video, false);
      ctx.clearRect(0,0,canvas.width,canvas.height);

      if (!preds || preds.length === 0) {
        hud.textContent = "Aucun visage détecté ❌";
        requestAnimationFrame(loop);
        return;
      }

      // on prend le premier visage
      const p = preds[0];
      const [x1,y1] = p.topLeft;
      const [x2,y2] = p.bottomRight;
      const w = x2 - x1, h = y2 - y1;

      // rectangle face
      ctx.lineWidth = Math.max(2, canvas.width/300);
      ctx.strokeStyle = "#00FF00";
      ctx.strokeRect(x1, y1, w, h);

      // debug: draw center
      ctx.fillStyle = "rgba(255,255,255,0.06)";
      ctx.fillRect((x1+x2)/2 - 2, (y1+y2)/2 -2, 4, 4);

      // get eyes: prefer landmarks
      let eyeA = null, eyeB = null;
      if (p.landmarks && p.landmarks.length >= 2) {
        // heuristique: prendre les 2 points les plus hauts (plus petit y)
        const lands = p.landmarks.slice();
        lands.sort((a,b) => a[1] - b[1]); // ascend y
        eyeA = lands[0];
        eyeB = lands[1];
        // ordonner left/right par x
        if (eyeA[0] > eyeB[0]) { const t=eyeA; eyeA=eyeB; eyeB=t; }
        console.log("Landmarks utilisés pour yeux:", eyeA, eyeB);
      } else {
        [eyeA, eyeB] = estimateEyesFromBox(p);
        console.log("Eyes estimés depuis bbox:", eyeA, eyeB);
      }

      // Draw eye markers
      ctx.fillStyle = "#FFD700";
      const r = Math.max(3, canvas.width/220);
      ctx.beginPath(); ctx.arc(eyeA[0], eyeA[1], r, 0, Math.PI*2); ctx.fill();
      ctx.beginPath(); ctx.arc(eyeB[0], eyeB[1], r, 0, Math.PI*2); ctx.fill();

      // Draw line between eyes
      ctx.strokeStyle = "#00FFFF";
      ctx.lineWidth = Math.max(2, canvas.width/600);
      ctx.beginPath(); ctx.moveTo(eyeA[0], eyeA[1]); ctx.lineTo(eyeB[0], eyeB[1]); ctx.stroke();

      // Draw centered square between eyes
      const midX = (eyeA[0]+eyeB[0])/2;
      const midY = (eyeA[1]+eyeB[1])/2;
      const boxSize = Math.max(6, canvas.width/160);
      ctx.fillStyle = "#FF0077";
      ctx.fillRect(midX - boxSize/2, midY - boxSize/2, boxSize, boxSize);

      // distance px
      const dx = eyeB[0] - eyeA[0];
      const dy = eyeB[1] - eyeA[1];
      const distPx = Math.hypot(dx, dy);

      // affichage HUD
      const conf = (p.probability && p.probability.length) ? Math.round(p.probability[0]*100) : "";
      hud.textContent = `Visage détecté ✅ ${conf?('| conf: '+conf+'%'):''} — dist yeux: ${Math.round(distPx)} px`;

    } catch (err) {
      console.error("Erreur boucle détection:", err);
      hud.textContent = "Erreur détection: " + (err.message || err);
    }

    requestAnimationFrame(loop);
  }

  loop();

})();
</script>
</body>
</html>
