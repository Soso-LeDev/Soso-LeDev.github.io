<!doctype html>
<html lang="fr">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>FaceID local — Enrol, Reconnaissance & Memoir.txt</title>
  <style>
    :root{--accent:#00ff99;--bg:#07121b;}
    html,body{height:100%;margin:0;background:var(--bg);font-family:Inter,system-ui,Segoe UI,Roboto,Arial;color:#e6eef8;}
    #app{height:100%;display:flex;flex-direction:column;}
    #stage{position:relative;flex:1;overflow:hidden;}
    video#videoEl, canvas#overlay{position:absolute; inset:0; width:100%; height:100%; object-fit:cover; transform:none;}
    #ui{position:fixed; right:12px; top:12px; width:360px; background:rgba(0,0,0,0.45); padding:12px; border-radius:10px; backdrop-filter: blur(6px); box-shadow: 0 8px 30px rgba(0,0,0,0.6);}
    label{display:block;margin-top:8px;font-size:13px;color:#cfeee0}
    input[type="text"]{width:100%; padding:8px;border-radius:6px;border:1px solid rgba(255,255,255,0.06);background:rgba(255,255,255,0.02);color:inherit}
    button{margin-top:8px;padding:8px 10px;border-radius:8px;border:none;cursor:pointer;background:var(--accent);color:#002; font-weight:600}
    .small{font-size:12px;opacity:0.85;margin-top:6px}
    #peopleList{max-height:140px; overflow:auto;margin-top:8px;border-radius:6px;padding:6px;background:rgba(255,255,255,0.02)}
    .personRow{display:flex;align-items:center;justify-content:space-between;padding:6px 4px;border-bottom:1px dashed rgba(255,255,255,0.03)}
    .personRow:last-child{border-bottom:0}
    .tag{font-size:13px;color:#001;padding:4px 8px;border-radius:999px;background:#d6ffe0}
    #status{font-family:monospace;font-size:13px;margin-top:6px;color:#bfeecf;}
  </style>
</head>
<body>
  <div id="app">
    <div id="stage">
      <video id="videoEl" autoplay muted playsinline></video>
      <canvas id="overlay"></canvas>
    </div>

    <div id="ui">
      <div style="display:flex;gap:8px;align-items:center;justify-content:space-between;">
        <div>
          <strong>FaceID local</strong><br><span class="small">Enrol / Recognize — Local only</span>
        </div>
        <div id="status">Initialisation...</div>
      </div>

      <label>Nom (pour enregistrer)</label>
      <input id="nameInput" type="text" placeholder="Ex: Soan_001"/>

      <div style="display:flex;gap:8px;">
        <button id="enrollBtn">Enregistrer visage</button>
        <button id="recognizeToggle">Activer recon</button>
      </div>

      <div style="display:flex;gap:8px;">
        <button id="exportDbBtn">Exporter DB JSON</button>
        <button id="exportMemoirBtn">Sauvegarder Memoir.txt</button>
        <input id="importFile" type="file" accept=".json" style="display:none"/>
        <button id="importBtn">Importer DB JSON</button>
      </div>

      <label>Profiles enregistrés</label>
      <div id="peopleList"></div>

      <div class="small" style="margin-top:6px;">
        <strong>Seuil reconnaissance :</strong> <span id="thresholdLabel">0.50</span>
      </div>
      <input id="threshold" type="range" min="0.25" max="0.8" step="0.01" value="0.5"/>

      <div class="small" style="margin-top:8px;">
        Notes : on stocke des <em>descriptors</em> (vecteurs). Pas d'image brute. Tout reste local.
      </div>
    </div>
  </div>

  <!-- face-api (vladmandic build) -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>

  <script>
  (async()=>{

    // ---- UI refs ----
    const videoEl = document.getElementById('videoEl');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const statusEl = document.getElementById('status');
    const nameInput = document.getElementById('nameInput');
    const enrollBtn = document.getElementById('enrollBtn');
    const recognizeToggle = document.getElementById('recognizeToggle');
    const peopleList = document.getElementById('peopleList');
    const exportDbBtn = document.getElementById('exportDbBtn');
    const importBtn = document.getElementById('importBtn');
    const importFile = document.getElementById('importFile');
    const exportMemoirBtn = document.getElementById('exportMemoirBtn');
    const thresholdRange = document.getElementById('threshold');
    const thresholdLabel = document.getElementById('thresholdLabel');

    let runningRecognition = false;
    let knownFaces = {}; // { name: { descriptor: [..], age: n, gender: 'male'|'female', created: ts } }
    const STORAGE_KEY = 'faceid_local_db_v2';
    let threshold = parseFloat(thresholdRange.value);

    // events log stored locally (array of objects)
    let memoirEvents = JSON.parse(localStorage.getItem('memoir_events_v1') || '[]');

    // ---- helpers ----
    function saveDB(){ localStorage.setItem(STORAGE_KEY, JSON.stringify(knownFaces)); renderPeopleList(); }
    function loadDB(){
      const raw = localStorage.getItem(STORAGE_KEY);
      if(raw){
        try{ knownFaces = JSON.parse(raw); }catch(e){ knownFaces = {}; }
      } else knownFaces = {};
      renderPeopleList();
    }
    function renderPeopleList(){
      peopleList.innerHTML = '';
      const entries = Object.entries(knownFaces);
      if(entries.length === 0) { peopleList.innerHTML = '<div class="small">Aucun profil enregistré</div>'; return; }
      for(const [name, meta] of entries){
        const row = document.createElement('div'); row.className='personRow';
        const left = document.createElement('div'); left.innerText = `${name} — ${meta.age ? Math.round(meta.age*10)/10 + ' ans' : 'âge ?'}`;
        const right = document.createElement('div');
        const tag = document.createElement('span'); tag.className='tag'; tag.innerText = 'Stored';
        const del = document.createElement('button'); del.innerText='Suppr'; del.style.marginLeft='8px';
        del.onclick = ()=>{ if(confirm('Supprimer '+name+' ?')){ delete knownFaces[name]; saveDB(); } };
        right.appendChild(tag); right.appendChild(del);
        row.appendChild(left); row.appendChild(right);
        peopleList.appendChild(row);
      }
    }

    function euclideanDistance(a,b){
      let sum=0;
      for(let i=0;i<a.length;i++){ const d=a[i]-b[i]; sum += d*d; }
      return Math.sqrt(sum);
    }

    function pushMemoirEvent(eventObj){
      memoirEvents.push(eventObj);
      localStorage.setItem('memoir_events_v1', JSON.stringify(memoirEvents));
    }

    // export Memoir.txt: try File System Access API first, fallback to download
    async function saveMemoirFile(filename='Memoir.txt'){
      const text = memoirEvents.map(e => JSON.stringify(e)).join('\n') + '\n';
      // try File System Access API
      if(window.showSaveFilePicker){
        try{
          const handle = await window.showSaveFilePicker({
            suggestedName: filename,
            types: [{ description: 'Text', accept: {'text/plain': ['.txt'] } }]
          });
          const writable = await handle.createWritable();
          await writable.write(text);
          await writable.close();
          alert('Memoir sauvegardé via File System API.');
          return;
        } catch(e){
          console.warn('FS API canceled or failed', e);
          // fallback to download
        }
      }
      // fallback: download blob
      const blob = new Blob([text], {type: 'text/plain;charset=utf-8'});
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = filename;
      document.body.appendChild(a);
      a.click();
      a.remove();
      URL.revokeObjectURL(url);
    }

    // ---- face-api models ----
    statusEl.textContent = 'Chargement modèles... (patiente)';
    await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
    await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
    await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
    await faceapi.nets.ageGenderNet.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
    statusEl.textContent = 'Modèles prêts.';
    loadDB();

    // ---- camera start ----
    async function startCamera(){
      try{
        const stream = await navigator.mediaDevices.getUserMedia({video:{width:1280,height:720}, audio:false});
        videoEl.srcObject = stream;
        await videoEl.play();
        resizeCanvas();
        statusEl.textContent = 'Caméra active';
        requestAnimationFrame(loop);
      } catch(e){
        console.error(e);
        alert('Erreur caméra: ' + e.message + '. Ouvre sur localhost/HTTPS.');
      }
    }

    function resizeCanvas(){
      canvas.width = videoEl.videoWidth || window.innerWidth;
      canvas.height = videoEl.videoHeight || window.innerHeight;
    }
    window.addEventListener('resize', resizeCanvas);

    // ---- enrollment: capture descriptor, store age/gender too ----
    enrollBtn.addEventListener('click', async ()=>{
      const name = (nameInput.value || '').trim();
      if(!name){ alert('Renseigne un nom.'); return; }
      statusEl.textContent = 'Capture pour ' + name + ' ...';
      // detect single face and descriptor
      const options = new faceapi.TinyFaceDetectorOptions({inputSize: 256, scoreThreshold: 0.5});
      const detection = await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks().withFaceDescriptor().withAgeAndGender();
      if(!detection){ alert('Aucun visage détecté. Approche-toi de la caméra.'); statusEl.textContent='Aucun visage'; return; }
      const descriptor = Array.from(detection.descriptor);
      const age = detection.age ? Math.round(detection.age*10)/10 : null;
      const gender = detection.gender || null;
      knownFaces[name] = { descriptor, age, gender, created: new Date().toISOString() };
      saveDB();
      statusEl.textContent = `${name} enregistré (age:${age}, gender:${gender})`;
      // log event
      pushMemoirEvent({
        type: 'enroll',
        name,
        age,
        gender,
        ts: new Date().toISOString()
      });
    });

    // ---- recognition toggle ----
    recognizeToggle.addEventListener('click', ()=> {
      runningRecognition = !runningRecognition;
      recognizeToggle.innerText = runningRecognition ? 'Désactiver recon' : 'Activer recon';
      statusEl.textContent = runningRecognition ? 'Reconnaissance ON' : 'Reconnaissance OFF';
    });

    // threshold slider
    thresholdRange.addEventListener('input', ()=>{ threshold = parseFloat(thresholdRange.value); thresholdLabel.innerText = threshold.toFixed(2); });

    // import/export DB
    exportDbBtn.addEventListener('click', ()=>{
      const data = { meta: { exported: new Date().toISOString() }, db: knownFaces };
      const blob = new Blob([JSON.stringify(data, null, 2)], {type: 'application/json'});
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a'); a.href = url; a.download = 'faceid_db.json'; document.body.appendChild(a); a.click(); a.remove(); URL.revokeObjectURL(url);
    });
    importBtn.addEventListener('click', ()=> importFile.click());
    importFile.addEventListener('change', async (ev)=>{
      const f = ev.target.files[0]; if(!f) return;
      const text = await f.text();
      try{
        const parsed = JSON.parse(text);
        if(parsed.db) knownFaces = parsed.db;
        else knownFaces = parsed;
        saveDB();
        alert('Import OK');
      }catch(e){ alert('Fichier invalide'); }
    });

    // export memoir
    exportMemoirBtn.addEventListener('click', ()=> saveMemoirFile());

    // ---- main loop: detect faces, draw, recognize if active ----
    async function loop(){
      if(videoEl.readyState >= 2){
        resizeCanvas();
        ctx.clearRect(0,0,canvas.width,canvas.height);
        // detect all faces
        const options = new faceapi.TinyFaceDetectorOptions({inputSize: 256, scoreThreshold: 0.5});
        const results = await faceapi.detectAllFaces(videoEl, options).withFaceLandmarks().withFaceDescriptors().withAgeAndGender();
        // draw boxes
        for(const res of results){
          const box = res.detection.box;
          // scale to canvas size
          const sx = box.x;
          const sy = box.y;
          const sw = box.width;
          const sh = box.height;
          // draw rect
          ctx.lineWidth = 3;
          ctx.strokeStyle = '#00ff99';
          ctx.strokeRect(sx, sy, sw, sh);
